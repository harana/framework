- action: generate_text
  inputs:
    max_tokens: int = 1000
    model: string = "default"
    prompt: string
    temperature: float = 0.7
  outputs:
    text: string
    tokens_used: int

- action: chat_completion
  inputs:
    max_tokens: int = 1000
    messages: list[ai_chat_message]
    model: string = "default"
    system_prompt: string
    temperature: float = 0.7
  outputs:
    response: string
    tokens_used: int

- action: generate_embeddings
  inputs:
    model: string = "default"
    text: string
  outputs:
    dimensions: int
    embeddings: list[float]

- action: generate_image
  inputs:
    model: string = "default"
    prompt: string
    quality: standard | hd = standard
    size: string = "1024x1024"
  outputs:
    base64: string
    url: string

- action: transcribe_audio
  inputs:
    audio: bytes
    language: string
    model: string = "default"
  outputs:
    duration: float
    text: string

- action: classify_text
  inputs:
    labels: list[string]
    model: string = "default"
    text: string
  outputs:
    confidence: float
    label: string
    scores: map[string, float]

- action: summarize_text
  inputs:
    max_length: int = 500
    model: string = "default"
    text: string
  outputs:
    summary: string

- action: extract_entities
  inputs:
    entity_types: list[string]
    model: string = "default"
    text: string
  outputs:
    entities: list[ai_entity]

- action: onnx_load_model
  inputs:
    model_path: string
    optimize: boolean = true
  outputs:
    input_shapes: list[ai_tensor_shape]
    model_id: string
    output_shapes: list[ai_tensor_shape]

- action: onnx_inference
  inputs:
    input_data: map[string, any]
    model_id: string
  outputs:
    inference_time_ms: float
    outputs: map[string, any]

- action: onnx_inference_bytes
  inputs:
    input_data: map[string, any]
    model_bytes: bytes
    optimize: boolean = true
  outputs:
    inference_time_ms: float
    outputs: map[string, any]

- action: onnx_model_info
  inputs:
    model_path: string
  outputs:
    input_names: list[string]
    input_shapes: list[ai_tensor_shape]
    output_names: list[string]
    output_shapes: list[ai_tensor_shape]

- action: onnx_unload_model
  inputs:
    model_id: string

- action: onnx_classify_image
  inputs:
    image: bytes
    labels: list[string]
    model_id: string
    top_k: int = 5
  outputs:
    inference_time_ms: float
    predictions: list[ai_classification_prediction]

- action: onnx_detect_objects
  inputs:
    confidence_threshold: float = 0.5
    image: bytes
    labels: list[string]
    model_id: string
    nms_threshold: float = 0.4
  outputs:
    detections: list[ai_object_detection]
    inference_time_ms: float

- action: onnx_text_embedding
  inputs:
    model_id: string
    text: string
  outputs:
    dimensions: int
    embedding: list[float]
    inference_time_ms: float

- object: ai_model
  schema:
    model_id: string
    name: string
    provider: string
    max_tokens: int
    temperature: float
    capabilities: list[string]

- object: ai_chat_message
  schema:
    role: string
    content: string

- object: ai_entity
  schema:
    text: string
    type: string
    start: int
    end: int
    confidence: float

- object: ai_tensor_shape
  schema:
    name: string
    dtype: string
    shape: list[integer]

- object: ai_classification_prediction
  schema:
    label: string
    confidence: float
    index: int

- object: ai_object_detection
  schema:
    label: string
    confidence: float
    x: float
    y: float
    width: float
    height: float

- object: ai_model_config
  schema:
    frequency_penalty: decimal = 0
    max_tokens: int
    model_id: string
    presence_penalty: decimal = 0
    stop_sequences: string
    temperature: decimal = 1.0
    top_p: decimal = 1.0

- object: ai_prompt_template
  schema:
    created_at: date = now()
    description: string
    is_active: boolean = true
    model_id: string
    system_prompt: string
    template: string
    updated_at: date = now()
    variables: string

- object: ai_conversation
  schema:
    created_at: date = now()
    metadata: string
    model_id: string
    status: active | archived | deleted = active
    title: string
    updated_at: date = now()
    user_id: string

- object: ai_message
  schema:
    content: string
    conversation_id: string
    created_at: date = now()
    metadata: string
    role: system | user | assistant | function | tool = user
    tokens_used: int

- object: ai_embedding
  schema:
    content: string
    created_at: date = now()
    dimensions: int
    metadata: string
    model_id: string
    source_id: string
    source_type: string
    vector: string

- object: ai_usage
  schema:
    completion_tokens: int = 0
    cost: decimal
    created_at: date = now()
    model_id: string
    prompt_tokens: int = 0
    request_type: chat | completion | embedding | image | audio = chat
    total_tokens: int = 0
    user_id: string
