- name: generate_content
  inputs:
    max_output_tokens: int = 1024
    model: gemini-pro | gemini-pro-vision | gemini-ultra = gemini-pro
    prompt: string #required
    safety_settings: list[gemini_safety_setting]
    stop_sequences: list[string]
    temperature: float = 0.7
    top_k: int = 40
    top_p: float = 0.95
  outputs:
    finish_reason: string
    safety_ratings: list[gemini_safety_rating]
    text: string
    usage: gemini_usage

- name: chat
  inputs:
    max_output_tokens: int = 1024
    messages: list[gemini_chat_message] #required
    model: gemini-pro | gemini-ultra = gemini-pro
    safety_settings: list[gemini_safety_setting]
    temperature: float = 0.7
    top_k: int = 40
    top_p: float = 0.95
  outputs:
    finish_reason: string
    response: string
    safety_ratings: list[gemini_safety_rating]
    usage: gemini_usage

- name: generate_multimodal
  inputs:
    audio: list[bytes]
    images: list[bytes]
    max_output_tokens: int = 1024
    model: gemini-pro-vision | gemini-ultra-vision = gemini-pro-vision
    prompt: string #required
    temperature: float = 0.4
    videos: list[bytes]
  outputs:
    finish_reason: string
    safety_ratings: list[gemini_safety_rating]
    text: string
    usage: gemini_usage

- name: stream_generate
  inputs:
    max_output_tokens: int = 1024
    model: gemini-pro | gemini-ultra = gemini-pro
    prompt: string #required
    temperature: float = 0.7
  outputs:
    stream_id: string
    success: boolean

- name: embed_content
  inputs:
    content: string #required
    model: embedding-001 = embedding-001
    task_type: retrieval_query | retrieval_document | semantic_similarity | classification | clustering
  outputs:
    dimensions: int
    embedding: list[float]

- name: batch_embed
  inputs:
    contents: list[string] #required
    model: embedding-001 = embedding-001
    task_type: retrieval_query | retrieval_document | semantic_similarity | classification | clustering
  outputs:
    count: int
    embeddings: list[gemini_embedding]

- name: count_tokens
  inputs:
    content: string #required
    model: gemini-pro | gemini-pro-vision | gemini-ultra = gemini-pro
  outputs:
    total_tokens: int

- name: list_models
  inputs:
    page_size: int = 50
    page_token: string
  outputs:
    models: list[gemini_model]
    next_page_token: string

- name: get_model
  inputs:
    model: string #required
  outputs:
    description: string
    display_name: string
    input_token_limit: int
    name: string
    output_token_limit: int
    supported_generation_methods: list[string]
    temperature: gemini_parameter_range
    top_k: gemini_parameter_range
    top_p: gemini_parameter_range

- name: analyze_image
  inputs:
    image: bytes #required
    model: gemini-pro-vision | gemini-ultra-vision = gemini-pro-vision
    prompt: string = "describe this image in detail"
    temperature: float = 0.4
  outputs:
    description: string
    safety_ratings: list[gemini_safety_rating]

- name: generate_code
  inputs:
    language: string
    max_output_tokens: int = 2048
    model: gemini-pro | gemini-ultra = gemini-pro
    prompt: string #required
    temperature: float = 0.2
  outputs:
    code: string
    explanation: string
    language: string

- name: summarize
  inputs:
    max_length: int = 500
    model: gemini-pro | gemini-ultra = gemini-pro
    style: brief | detailed | bullet_points = brief
    text: string #required
  outputs:
    original_length: int
    summary: string
    summary_length: int

- name: translate
  inputs:
    model: gemini-pro | gemini-ultra = gemini-pro
    source_language: string
    target_language: string #required
    text: string #required
  outputs:
    detected_source_language: string
    translated_text: string

- name: extract_structured
  inputs:
    model: gemini-pro | gemini-ultra = gemini-pro
    schema: extract_schema #required
    text: string #required
  outputs:
    confidence: float
    data: extracted_data

- name: gemini_model
  class:
    model_id: string
    name: string
    version: string
    input_token_limit: int
    output_token_limit: int
    supported_generation_methods: list[string]

- name: gemini_safety_setting
  class:
    category: string
    threshold: string

- name: gemini_safety_rating
  class:
    category: string
    probability: string
    blocked: boolean

- name: gemini_usage
  class:
    prompt_token_count: int
    candidates_token_count: int
    total_token_count: int

- name: gemini_chat_message
  class:
    role: string
    content: string

- name: gemini_embedding
  class:
    values: list[float]
    dimensions: int

- name: gemini_parameter_range
  class:
    min: float
    max: float
    default: float

- name: extract_schema
  class:
    fields: list[extract_schema_field]

- name: extract_schema_field
  class:
    name: string
    type: string
    description: string
    required: boolean

- name: extracted_data
  class:
    values: map[string, any]
